{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa2b0f0-30c9-4c9b-b3e2-7290008ec84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db65f643-68f2-4ed7-a8e9-7cf1ed76ffda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'setting.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Scrapping junglescout.com to get niche product of amazon\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# by the way, with this code below we can only get about <2000 records because the id of product and group id is dynamic\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# I have no idea for this issue now :(\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetting.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data_file:    \n\u001b[0;32m      6\u001b[0m     sv \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(data_file)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\" setting.json\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m{'avr price max': '100',\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m 'avr price min': '0',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m 'review max': 2000,\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m 'review min': 0} \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'setting.json'"
     ]
    }
   ],
   "source": [
    "# Scrapping junglescout.com to get niche product of amazon\n",
    "# by the way, with this code below we can only get about <2000 records because the id of product and group id is dynamic\n",
    "# I have no idea for this issue now :(\n",
    "\n",
    "with open('setting.json') as data_file:    \n",
    "    sv = json.load(data_file)\n",
    "\"\"\" setting.json\n",
    "{'avr price max': '100',\n",
    " 'avr price min': '0',\n",
    " 'avr units solds max': '2000',\n",
    " 'avr units solds min': '400',\n",
    " 'limit page': 2,\n",
    " 'limit weight': 1,\n",
    " 'max page': 10,\n",
    " 'price max': 60,\n",
    " 'price min': 15,\n",
    " 'rank max': 2000,\n",
    " 'rank min': 400,\n",
    " 'review max': 2000,\n",
    " 'review min': 0} \"\"\"\n",
    "# Login to web with url: https://members.junglescout.com/users/sign_in.json and get token\n",
    "# niche_url = \"https://members.junglescout.com/#/niche\"\n",
    "\n",
    "body = {\"user\":{\"login\":christopherkntu@gmail.com, \"password\":'Trockmanimes#132'}}  \n",
    "myurl = \"https://members.junglescout.com/users/sign_in.json\"\n",
    "\n",
    "req = urllib.request.Request(myurl)\n",
    "req.add_header('Content-Type', 'application/json; charset=utf-8')\n",
    "jsondata = json.dumps(body)\n",
    "jsondataasbytes = jsondata.encode('utf-8')   # needs to be bytes\n",
    "req.add_header('Content-Length', len(jsondataasbytes))\n",
    "response = urllib.request.urlopen(req, jsondataasbytes)\n",
    "bsObj0 = BeautifulSoup(response, \"lxml\")\n",
    "dict1 = bsObj0.find(\"p\").get_text()\n",
    "dict1 = dict1[50:]\n",
    "token = dict1[:32]\n",
    "print(token)\n",
    "\n",
    "# Request to get content of page include the product group id\n",
    "getid_url = \"http://members.junglescout.com/api/v1/keywords/get_keywords?query=towel&direction=desc&column=opportunity_score&per_page=200&page=2&initialPageLoad=false&averagePriceMin=0&averagePriceMax=100&competitionMin=0&competitionMax=100&demandMin=0&demandMax=1000&listingQualityScoreMin=0&listingQualityScoreMax=100&opportunityScoreMin=0&opportunityScoreMax=100&wordCountMin=1&wordCountMax=4&country=us&categories=%5B%22Baby%22%5D\"\n",
    "req2 = urllib.request.Request(getid_url)\n",
    "req2.add_header('token', token)\n",
    "req2.add_header('Content-Type', 'application/json; charset=utf-8')\n",
    "req2.add_header('Host', 'members.junglescout.com')\n",
    "req2.add_header('Connection', 'keep-alive')\n",
    "\n",
    "response2 = urllib.request.urlopen(req2)\n",
    "# print(response2.headers)\n",
    "bsObj = BeautifulSoup(response2, \"lxml\")\n",
    "print(bsObj)\n",
    "# Parse bsObj to get group product id\n",
    "p_tag = bsObj.find(\"p\").get_text()\n",
    "d = json.loads(p_tag)\n",
    "e = d[\"data\"]\n",
    "g = e[\"keywords\"]\n",
    "list_id = []\n",
    "for item in g:\n",
    "    id_ = item[\"id\"]\n",
    "    list_id.append(id_)\n",
    "list_id\n",
    "\n",
    "\"\"\"\n",
    "It will response a id list like this\n",
    "[44559098,\n",
    " 44518201,\n",
    " 39413267,\n",
    " 39413369,\n",
    " 39413425,\n",
    " 44505012,\n",
    " ...\n",
    " 44573980,\n",
    " 48741489,\n",
    " 49657530]\n",
    " \"\"\"\n",
    " # Request to get product\n",
    "get_prd = \"http://members.junglescout.com/api/v1/keywords/keyword_data?id=44505012\" #+ str(id_)\n",
    "req3 = urllib.request.Request(get_prd)\n",
    "req3.add_header('token', token)\n",
    "req3.add_header('Content-Type', 'application/json; charset=utf-8')\n",
    "req3.add_header('Host', 'members.junglescout.com')\n",
    "req3.add_header('Connection', 'keep-alive')\n",
    "\n",
    "response3 = urllib.request.urlopen(req3)\n",
    "# print(response2.headers)\n",
    "bsObj2 = BeautifulSoup(response3, \"lxml\")\n",
    "\n",
    "# Parse json to get product detail : each column is a list\n",
    "p_tag2 = bsObj2.find(\"p\").get_text()\n",
    "d2 = json.loads(p_tag2)\n",
    "e2 = d2[\"data\"]\n",
    "g2 = e2[\"products\"]\n",
    "\n",
    "# Create list-column of variables\n",
    "list_product_name = []\n",
    "list_product_link = []\n",
    "list_product_review = []\n",
    "list_product_price = []\n",
    "list_product_rank = []\n",
    "list_product_estsale = []\n",
    "list_product_revenue = []\n",
    "\n",
    "g2[0]\n",
    "\"\"\"\n",
    "{'all_fees': {'fulfillment_fee': 2.99,\n",
    "  'referral_fee': 1.95,\n",
    "  'total_fee': 4.94,\n",
    "  'variable_closing_fee': 0.0},\n",
    " 'amz_store_code': 'us',\n",
    " 'amz_store_id': None,\n",
    " 'asin': 'B01I5MPR1G',\n",
    " 'brand': 'Mukin',\n",
    " 'bsr_product': True,\n",
    " 'calc_category': 'Baby',\n",
    " 'calc_estimated_revenue': 11691.0,\n",
    " 'calc_net': '8.02',\n",
    " 'category': 'Baby',\n",
    " 'country': None,\n",
    " 'created_at': '2016-08-25T13:45:32.943Z',\n",
    " 'fba_fee': '4.97',\n",
    " 'height': 1.5,\n",
    " 'id': 47921767,\n",
    " 'image_url': 'https://images-na.ssl-images-amazon.com/images/I/51NJdg8EFLL._SL75_.jpg',\n",
    " 'index_elasticsearch': True,\n",
    " 'last_indexed_at': '2017-05-08T12:56:37.832Z',\n",
    " 'last_scraped': 'May 6, 2017',\n",
    " 'length': 8.3,\n",
    " 'listing_quality_score': 65.0,\n",
    " 'number_sellers': 3,\n",
    " 'parent_asin': None,\n",
    " 'pd_est_sales': 900,\n",
    " 'pd_price': '12.99',\n",
    " 'pd_rank': 1287,\n",
    " 'price': 12.99,\n",
    " 'product_name': 'Baby Muslin Washcloths and Towels - Natural Organic Cotton Baby Wipes - Soft Newborn Baby Face Towel and Muslin Washcloth for Sensitive Skin- Baby Registry as Shower Gift, 5 Pack 10x10 inches By Mukin',\n",
    " 'product_tier': 'Standard (Large)',\n",
    " 'product_url': 'http://www.amazon.com/dp/B01I5MPR1G',\n",
    " 'rating': 4.4,\n",
    " 'review_datum': {'rating': 4.4, 'reviews': 25},\n",
    " 'reviews': 25,\n",
    " 'seller': 'Mukin',\n",
    " 'seller_type': 'FBA',\n",
    " 'state': 'active',\n",
    " 'unavailable': False,\n",
    " 'updated_at': '2017-05-08T12:56:12.129Z',\n",
    " 'variants': False,\n",
    " 'weight': 0.25,\n",
    " 'width': 5.6}\n",
    " \"\"\"\n",
    "df_prd = pd.DataFrame(columns=('1.Product Name', '2.Product Link', '3.Review', '4.Price', '5.Rank', '6.EST Sales', '7.Revenue') )\n",
    "for item in g2:\n",
    "    item_detail = {\"1.Product Name\": item[\"product_name\"],\n",
    "                           \"2.Product Link\": item[\"product_url\"],\n",
    "                           \"3.Review\": item[\"reviews\"],\n",
    "                           \"4.Price\": item[\"price\"],\n",
    "                           \"5.Rank\": item[\"pd_rank\"],\n",
    "                           \"6.Weight\": item[\"weight\"],\n",
    "                           \"7.EST Sales\": item[\"pd_est_sales\"],\n",
    "                           \"8.Revenue\": item[\"calc_estimated_revenue\"]}\n",
    "    df_prd = df_prd.append(item_detail, ignore_index=True)\n",
    "df_prd # The result is df_prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e13c8-5d40-42d4-8a6a-d4997e9fff06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
